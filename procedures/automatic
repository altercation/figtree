#!/bin/bash

# Ethan Schoonover <es@ethanschoonover.com>

# command line tests:
# aif -p http://github.com/altercation/archproto/raw/master/procedures/automatic -c systems/lenovo/x220
# aif -p archproto/automatic -c https://github.com/altercation/archproto/systems/lenovo/x220/profile

# archproto/automatic
# aif procedure to install a various prototype configurations
# including hardware prototypes for specific makes/models,
# environment prototypes for common wm/de configurations
# application set prototypes (e.g. lightweight-cli apps)
# user protytpes

# also takes a user customized aif profile using archproto specific functions

# defined herein:
#
# additional custom worker(s)
# custom command line parameter handling
# revised http remote module sourcing to enable overlay, etc.
# revised profile/config source heuristic to be smart (but not too smart) about 
# where to get the specified profiles from
# addition to phases to include correct worker(s)
#
# we also define and redefine some lib functions, notably those related to 
# loading libs, files, etc. The reason for these redefined functions is that we 
# want to be able to source those file remotely, be smart (but not too smart) 
# about the path searched for those files and enable loading new types of files 
# such as the system prototype profiles. Finally we have to redefine these here 
# rather than a library script because this is the only file we can load from 
# aif remotely.

ARCHPROTO_MODULE_NAME=archproto # in case we need to change our script name 
DOWNLOADS_DIR="${RUNTIME_DIR}/${ARCHPROTO_MODULE_NAME}-downloads"; [[ -e "$DOWNLOADS_DIR" ]] && rm -rf "$DOWNLOADS_DIR"; mkdir -p "$DOWNLOADS_DIR"
#TEMP_DIR="${RUNTIME_DIR}/${ARCHPROTO_MODULE_NAME}-downloads"; [[ -e "$TEMP_DIR" ]] && rm -rf "$TEMP_DIR"; mkdir -p "$TEMP_DIR"
KNOWN_SUBDIRS=(procedures libs profiles systems environments applications users examples) # standard subdirectory names for archproto/aif

AIF_MODULE_NAME="$module" # from aif.sh
AIF_PROCEDURE_PATH="$procedure" # from aif.sh
MODULE_PATHS=("$(dirname $(dirname ${AIF_PROCEDURE_PATH}))") # this works in both cases of module being either http or local

depend_procedure core automatic # most of automatic fits our needs
phase_system+=(change_configvalues write_overlayfiles system_extras) # archproto custom workers (see below)
var_RUNTIME_REPOSITORIES=(archlinuxfr "Server = http://repo.archlinux.fr/${var_ARCH}")
var_RUNTIME_PACKAGES="augeas yaourt" # use yaourt instead of pacman as systems may require AUR packages
var_OPTS_STRING="c:r:" #var_OPTS_STRING="c:s:e:u:a:r:"

# !!!!!TODO: it's possible we have to call some reconfig at end of phase_system due to possible changes impacting mkinitcpio
# the worker to call is configure_system. it's actually ok to call the second default function (post_configure target) several times
# though maybe better to either redefine configure_system, move it to the end, or have another post-configure worker at the end of the phase_system

# ---------------------------------------------------------------------
# following two lines from dieter's automatic procedure, for ref
# TODO: implement setting hostname, keymap, consolefont, network settings, root 
# for a list of recognized variables, see examples/generic-install-on-sda
# ---------------------------------------------------------------------

read -r -d '' var_ARGS_USAGE <<-'EOF'
-s <make/model>:    Specify a make/model prototype AIF system profile to install. If specified as simply "make/model" the path of the 
                    archproto module as specified in the -p parameter will be used. This allows for specifying the following:

                        aif -p archproto/automatic -s lenovo/x120e

                    and aif will automatically source the system profile from:
EOF
dfunc()
{
    # debug function, better info than "caller"
    # called without parameters at top of function; reports where it was called 
    # from (calling function and line number)
    echo ">>> ${FUNCNAME[1]}() called at line ${BASH_LINENO[1]} by ${FUNCNAME[2]}"
}

process_args ()
{
    dfunc
    var_AUTOMATIC_PROFILE=
    while [[ -n $1 ]]
    do
        case $1 in
            -c) [[ -n "$2" ]] && var_AUTOMATIC_PROFILE=$2 || die_error "You must specify an aif config profile when using the -c flag." ;;
            -r) [[ -n "$2" ]] && REPO_TYPE=$2 || die_error "You must specify an aif config profile when using the -c flag." ;;
            *) usage && exit 5 ;;
        esac
        shift 2
    done
}
source_and_overlay() { dfunc; local revert_overlay=$OVERLAY; OVERLAY="$(dirname '$1')/overlay"; source $1; OVERLAY=$revert_overlay; unset revert_overlay; }
makelocal() { echo "$DOWNLOADS_DIR/${1:$(expr "$1" : 'https*://')}"; }
maketemp() { echo "$TEMP_DIR/${1:$(expr "$1" : 'https*://')}"; }
conform_repo ()
{
# TODO: this could be made more intelligent (or maybe too clever) by cloning the repo successfully to a temp directory (e.g. temp/archproto) regardless of
# what URL is given, so if we give a *raw* url for a github repo (say, for the aif procedure), we can still clone the repository and then once it is in temp
# we know that the newly cloned repo is our module root, and we can move it into our downloads root and add it to our path.
    dfunc
    local repo_remote=$1
    local repo_local=
    local repo_type=${REPO_TYPE:-} # from optional -r command line argument
    if [[ -n "$repo_type" ]]; then : # $repo_type already set
    elif [ $(expr "$repo_remote" : 'https*://.*github.com') -gt 0 ]; then repo_type=git
    elif [ $(expr "$repo_remote" : '.*/git/') -gt 0 ]; then repo_type=git
    elif [ $(expr "$repo_remote" : 'https*://.*bitbucket.org') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$repo_remote" : '.*/hg/') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$repo_remote" : '.*/mercurial/') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$repo_remote" : '.*/svn/') -gt 0 ]; then repo_type=svn
    fi
    local repo_command=
    local repo_suffix=
    case $repo_type in
        git) repo_command="git clone --depth=0" && repo_suffix=".git";;
        hg)  repo_command="hg clone" ;;
        svn) repo_command="svn checkout" ;;
    esac
    while [[ -n "$repo_remote" && ${#repo_remote} > 1 ]]; 
    do
        local repo_local=$(makelocal "$repo_remote")
        if [[ -e "$repo_local" ]] 
        then
                echo "FOUND LOCAL REPO at $repo_local"
                return 0
        elif $repo_command "$repo_remote" "$repo_local" &>/dev/null
        then
                return 0
        else
                # failed so we *must* remove the failed target directory here, otherwise we end up with a false positive later
                rm -rf "$repo_local" "$(dirname $repo_local)"
        fi
        repo_remote=$(dirname "$repo_remote") # trim and retry
    done
    die error "failed to download repo from path $1"
}
load_profile()
{
    dfunc
    echo "with args $*"
    # arguments:
    # $1 (assigned to profile_path): a path, either relative, absolute local or remote URL
    # $2 is the *original* type of profile (relative, remote, absolute) and is only set from insid the function
    # expects/uses state:
    # OVERLAY: current value of OVERLAY directory path
    # MODULE_PATHS: array of paths to use, in order, as module roots with relative paths
    local profile_path=${1%/} # strips any trailing slash
    local profile_type=${2:-}
    if [[ "${profile_path:0:1}" == "/" ]]; then # absolute local path
        [[ "${profile_type}" != "xrelative" ]] && update_modulepaths_from_profilepath "$profile_path" # add to module paths (thus if we've donwloaded a repo, we'll check locally next time)
        [[ -d "${profile_path}" ]] && profile_path="$profile_path/profile"
        [[ -f "${profile_path}" ]] && source_and_overlay "$profile_path" || return 1
    elif [[ "${profile_path:0:4}" == "http" ]]; then # remote url, could be http or https with this match
        # no update_modulepaths_from_profilepath needed here; it's taken care 
        # of in absolute since that means we've already successfully downloaded 
        # a repository
        [[ $(conform_repo "$profile_path") ]] && (load_profile "$(makelocal ${profile_path})" ${profile_type:-http} || return 1 ) || die_error "(shouldn't reach this) error cloning repo for $profile_path"
    else # assumed relative path (e.g. profiles/profilename)
        for module_root in ${MODULE_PATHS[@]}; do load_profile "${module_root%/}/${profile_path#/}" "relative" && return 0; done; return 1
    fi
}
depend_profile() { load_profile "$1"; }
update_modulepaths_from_profilepath()
{
    dfunc
    echo "MODULE_PATHS IS CURRENTLY: ${MODULE_PATHS[@]}"
    echo "called with args $*"
    # expects parameters:
    # $1: a local absolute path or http remote *profile* path we need to make some assumptions about either the depth of all profile paths or standard names 
    # such as procedure, systems, etc. this is the trickiest assumption we make and the only other option I see is to never allow a relative path, which is silly.
    # requires state: $KNOWN_SUBDIRS
    # modifies state: $MODULE_PATHS
    local module_path=${1%profile} # strip profile
    module_path=${module_path%/} # strip trailing slash
    while [[ -n "$module_path" && ${#module_path} > 1 ]]; do
        for known_subdir in ${KNOWN_SUBDIRS[@]}; do
        echo ">>>>>>> )))))))))))))))))))))))))) testing $known_subdir against $(basename $module_path)"
            if [[ "$(basename $module_path)" == "$known_subdir" ]]
            then
                # we have a match and assume we are one level away from root || trim and loop
                module_path="$(dirname $module_path)"
                # now check to see if this path is already in MODULE_PATHS
                for test_path in ${MODULE_PATHS[@]}; do [[ "$test_path" == "$module_path" ]] && return 0; done
                # still here, add path to MODULE_PATHS
                MODULE_PATHS=("$module_path" "${MODULE_PATHS[@]}")
                echo "MODULE_PATHS IS NOW UPDATED TO: ${MODULE_PATHS[@]}"
                return 0
            fi
        done
        module_path="$(dirname $module_path)" # no match, trim a level
    done
    # if we are still here then we didn't find a "known subdir"... best to error out here, though another option is to just strip the last two / three 
    # path components. we could try to standardize all "known" subdir formats to: modulename/knownsubidr/category/specificprofile, eg:
    # archproto/systems/lenovo/x220 or archproto/environments/xmonad/es
    die_error "failed to find known subdirectory (one of ${KNOWN_SUBDIRS[@]}) in path $1;"
}
worker_intro () { notify "AIF archproto automatic procedure using initial profile $archproto_PROFILE"; }
worker_configure ()
{
        dfunc
        var_UI_TYPE=${arg_ui_type:-cli}
        ui_init
        [ -z "$var_AUTOMATIC_PROFILE" ] && die_error "You must specify a config file to use this procedure"
        load_profile $var_AUTOMATIC_PROFILE || die_error "Failed to load profile $var_AUTOMATIC_PROFILE from paths $MODULE_PATHS"
        #source $var_AUTOMATIC_PROFILE   || die_error "Could not source config $var_AUTOMATIC_PROFILE"
        # Check mandatory options
        [ -z "$PARTITIONS" ] && die_error "You did not specify a partition scheme"
        [ -z "$BLOCKDATA"  ] && die_error "You did not specify a partition scheme"
        [ -z "$GRUB_DEVICE" ] && die_error "You did not specify a grub device"
        # initialize internal variables based on variables set by the user (some of the vars are handled in other workers):
        var_RUNTIME_REPOSITORIES=$RUNTIME_REPOSITORIES
        var_RUNTIME_PACKAGES=$RUNTIME_PACKAGES
        var_GRUB_DEVICE=$GRUB_DEVICE
        var_PARTITIONS=$PARTITIONS
        var_BLOCKDATA=$BLOCKDATA
        HARDWARECLOCK=${HARDWARECLOCK:-localtime}
        TIMEZONE=${TIMEZONE:-Canada/Pacific}
}
worker_install_packages()
{
    dfunc
    # from dieter's examples in unofficial subdir of aif github repo
    # better to do this here rather than redefine PACMAN & PACMAN_TARGET?
    true
    return
    #       PACMAN_BACKUP=$PACMAN
    #       PACMAN_TARGET_BACKUP=$PACMAN_TARGET
    #       PACMAN=${PACMAN//pacman/yaourt}
    #       PACMAN_TARGET=${PACMAN_TARGET//pacman/yaourt}
    #
    #       target_prepare_pacman core extra community
    #       [ -z "$TARGET_PACKAGES" ] && die_error "No packages listed for installation!"
    #       installpkg
    #
    #       PACMAN=$PACMAN_BACKUP
    #       PACMAN_TARGET=$PACMAN_TARGET_BACKUP
}

worker_change_configvalues()
{
        dfunc
        write_config_changes $CONFIG_CHANGES
}

worker_write_overlayfiles()
{
        dfunc
        # This is more problematic as we have to include the correct prefix path
        # and make sure to source it properly if local/remote, etc.
        # the add overlay files function will have to correctly assign a full path
        write_overlayfiles $OVERLAY_FILES
}

worker_system_extras()
{
        dfunc
        system_extras
}

# $1 array of packages (from official and aur) to add to TARGET_PACKAGES
# installed via standard installation functions
add_packages() { dfunc; [[ -n "$1" ]] && TARGET_PACKAGES+=" $1" || true; }

# $1 array of changes in augeas format to add to CONFIG_CHANGES
# later written out with write_config_changes()
add_config_changes() { dfunc; [[ -n "$1" ]] && CONFIG_CHANGES+=" $1"  || true; }

# $1 array of (final root relative) config files to add to OVERLAY_FILES
# later written out with write_overlay_files()
add_overlay_files() { dfunc; [[ -n "$1" ]] && OVERLAY_FILES+=" $1"   || true; }

write_config_changes()
{
        dfunc
        true
        echo "CONFIG CHANGES TO BE WRITTEN:"
        echo "$CONFIG_CHANGES"
        # iterate through array of config changes
        # write changes using augeas or custom function
}

write_overlay_files()
{
        dfunc
        true
        echo "OVERLAY FILES TO WRITE"
        echo "$OVERLAY_FILES"
        # iterate over list of overlay files
        # write files using current file permissions
        # backup original file?
}

# this is a catch all function that any system profile can override
# to do anything that needs doing (custom sed commands, etc.)
# (so a profile in archproto/systems/make/model/profile can override
# this arbitrarily)
system_extras()
{
        dfunc
        true
}

#!/bin/bash

# Ethan Schoonover <es@ethanschoonover.com>

# command line tests:
# aif -p http://github.com/altercation/archproto/raw/master/procedures/automatic -c systems/lenovo/x220
# aif -p archproto/automatic -c https://github.com/altercation/archproto/systems/lenovo/x220/profile

# archproto/automatic
# aif procedure to install a various prototype configurations
# including hardware prototypes for specific makes/models,
# environment prototypes for common wm/de configurations
# application set prototypes (e.g. lightweight-cli apps)
# user protytpes

# also takes a user customized aif profile using archproto specific functions

# defined herein:
#
# additional custom worker(s)
# custom command line parameter handling
# revised http remote module sourcing to enable overlay, etc.
# revised profile/config source heuristic to be smart (but not too smart) about 
# where to get the specified profiles from
# addition to phases to include correct worker(s)
#
# we also define and redefine some lib functions, notably those related to 
# loading libs, files, etc. The reason for these redefined functions is that we 
# want to be able to source those file remotely, be smart (but not too smart) 
# about the path searched for those files and enable loading new types of files 
# such as the system prototype profiles. Finally we have to redefine these here 
# rather than a library script because this is the only file we can load from 
# aif remotely.

# ----------------------------------------------------------------------
# procedure specific definitions
# ----------------------------------------------------------------------

[[ "$NOFAILSAFE" != "1" && ! -e /arch ]] && die_error "FAILSAFE TRIPPED: no /arch directory present, looks like an installed system\nOverride this by: \`export NOFAILSAFE=1\`"

depend_procedure core automatic # most of automatic fits our needs, up top so we can override the phases and values it sets below

# set these after the depend_procedure to ensure we override any values therein
# we will further override or add to some of the values below (RUNTIME_...) after sourcing profiles in worker_configure
var_ARCHPROTO_MODULE_NAME=archproto # in case we need to change our script name 
var_ARCHPROTO_PROCEDURE_SUBPATH=/procedures/automatic
var_DOWNLOADS_DIR="${RUNTIME_DIR}/${var_ARCHPROTO_MODULE_NAME}-downloads"
[[ -e "$var_DOWNLOADS_DIR" ]] && rm -rf "$var_DOWNLOADS_DIR"; mkdir -p "$var_DOWNLOADS_DIR"
var_KNOWN_SUBDIRS=(procedures libs profiles systems environments applications users examples) # standard subdirectory names for archproto/aif
[[ "$module" != "http" ]] && var_AIF_PROCEDURE_PATH="$procedure" || var_AIF_PROCEDURE_PATH="$2"
var_MODULE_PATHS[0]="${var_AIF_PROCEDURE_PATH%$var_ARCHPROTO_PROCEDURE_SUBPATH*}"
var_RUNTIME_REPOSITORIES=(core "http://mirrors.kernel.org/archlinux/core/os/$var_ARCH" archlinuxfr "http://repo.archlinux.fr/${var_ARCH}")
#var_RUNTIME_REPOSITORIES=(archlinuxfr "http://repo.archlinux.fr/${var_ARCH}")
var_RUNTIME_PACKAGES="git yaourt" # var_RUNTIME_PACKAGES="yaourt git mercurial svn augeas"
var_OPTS_STRING="c:r:" #var_OPTS_STRING="c:s:e:u:a:r:"

# rc/config default values if not set previously or by user
# note that in user created profiles these are specified by the same variable names without the "default_" prefix. See the _template profiles for details
# these are not prefixed by "var_" so we remember that these are not used elsewhere in the procedure (other than one-time default assignment)
# 
# this is different from items with a var_ previx in an important way: defaul_ variables can be completely overriden, as I use them here
# while var_ varialbes (such as var_RUNTIME_REPOSITORIES) that are set above in this procedure are retained (and possibly added to user values)
# so, for example, var_RUNTIME_REPOSITORIES retains the value assigned above and takes any extra values the user has assigned to RUNTIME_REPOSITORIES
# in their profiles
default_LOCALE="en_US.UTF-8"
default_DAEMON_LOCALE="no"
default_HARDWARECLOCK="UTC"
default_TIMEZONE="Canada/Pacific"
default_KEYMAP="us"
default_CONSOLEFONT=
default_CONSOLEMAP=
default_USECOLOR="yes"
default_TESTVAL1="default value 1"
default_TESTVAL1="default value 2"

# Install source defaults
# again, these will be overridden by equivalent (sans default_) variables assigned in profiles
#
# OK: these are *NOT* used in develop branch anymore...
#default_SOURCE=net
#default_FILE_URL=file:///src/core/pkg
#default_SYNC_URL= #'http://mirrors.kernel.org/archlinux/$repo/os/$arch'

if [ -d /repo/core ]; then
        TARGET_REPOSITORIES=(core 'file:///repo/$repo/$arch')
else
        MIRROR='ftp://mirrors.kernel.org/archlinux/$repo/os/$arch'
        TARGET_REPOSITORIES=(core $var_MIRRORLIST) # $var_MIRRORLIST is set by AIF
fi

# Filesystem defaults
# not critical
# default_PART_ACCESS=dev # can be set to 'uuid', 'dev', 'label', or leave empty for 'dev'

#if net is install source, we should if/then for sync_url presence?



#phase_preparation=(runtime_network runtime_repositories runtime_packages configure profile intro sysprep select_source)
#phase_basics=()
#phase_system=()
# we reorder phase_preparation so that, if for some reason we're running as a local procedure from install media, we set up the network first
# and bring in the required runtime packages (primarily for our vcs remote sourcing)
phase_preparation=(intro runtime_network runtime_repositories runtime_packages configure select_source)
phase_basics=(set_clock prepare_disks) # defaults, here for ref/override
phase_system=(package_list install_packages configure_system install_bootloader) # defaults, here for ref/override
phase_system+=(write_configs write_overlay system_misc) # archproto custom workers (see below)
phase_finish=(msg_report) # defaults

# !!!!!TODO: it's possible we have to call some reconfig at end of phase_system due to possible changes impacting mkinitcpio
# the worker to call is configure_system. it's actually ok to call the second default function (post_configure target) several times
# though maybe better to either redefine configure_system, move it to the end, or have another post-configure worker at the end of the phase_system

# ---------------------------------------------------------------------
# following two lines from dieter's automatic procedure, for ref
# TODO: implement setting hostname, keymap, consolefont, network settings, root 
# for a list of recognized variables, see examples/generic-install-on-sda
# ---------------------------------------------------------------------

read -r -d '' var_ARGS_USAGE <<-'EOF'
-s <make/model>:    Specify a make/model prototype AIF system profile to install. If specified as simply "make/model" the path of the 
                    archproto module as specified in the -p parameter will be used. This allows for specifying the following:

                        aif -p archproto/automatic -s lenovo/x120e

                    and aif will automatically source the system profile from:
EOF

# ----------------------------------------------------------------------
# procedure workers
# ----------------------------------------------------------------------

worker_intro ()
{

notify "\
===============================================================================\n\
AIF archproto automatic procedure using initial profile:\n\
$var_AIF_PROCEDURE_PATH\n\
===============================================================================\n"
}

worker_runtime_packages ()
{
    $PACMAN -Sy pacman --noconfirm || return 1 # update pacman first to avoid having to run twice
    for pkg in $var_RUNTIME_PACKAGES; do $PACMAN -Sy --noconfirm --needed $pkg || return 1; done
    #PACMAN=yaourt
    # TODO: change PACMAN and PACMAN_TARGET
    return 0
}

worker_configure ()
{
    
    inform "Starting system configuration and profile load sequence..."

    var_UI_TYPE=${arg_ui_type:-cli}
    ui_init
    [ -z "$var_AUTOMATIC_PROFILE" ] && die_error "You must specify a config file to use this procedure"

    # here we import our profile(s) to allow default values to be overridden
    load_profile $var_AUTOMATIC_PROFILE || die_error "Failed to load profile $var_AUTOMATIC_PROFILE from paths $var_MODULE_PATHS"

    # make sure we have values for the following (could these be set as defaults safely?)
    [ -z "$PARTITIONS" ] && die_error "You did not specify a partition scheme"
    [ -z "$BLOCKDATA"  ] && die_error "You did not specify a partition scheme"
    [ -z "$GRUB_DEVICE" ] && die_error "You did not specify a grub device"

    var_RUNTIME_REPOSITORIES+=($RUNTIME_REPOSITORIES) # MUST BE IN AN ARRAY
    var_RUNTIME_PACKAGES+=" $RUNTIME_PACKAGES"
    var_GRUB_DEVICE=$GRUB_DEVICE
    var_PARTITIONS=$PARTITIONS
    var_BLOCKDATA=$BLOCKDATA
    set_values_with_default_fallbacks="LOCALE DAEMON_LOCALE HARDWARECLOCK TIMEZONE KEYMAP CONSOLEFONT CONSOLEMAP USECOLOR"
}

debug_report_values()
{
    echo "================================================================================"
    local valuelist=$@
    for valname in $valuelist
    do
        echo "$valname=${!valname}"
    done
    echo "================================================================================"
    echo "enter to continue..."
    read answer
}
debug_report_next()
{
    echo "================================================================================"
    echo "about to execute:"
    echo "$*"
    echo "================================================================================"
    echo "enter to continue..."
    read answer
}

worker_select_source ()
{
        var_PKG_SOURCE_TYPE=${SOURCE:-cd}
        var_FILE_URL=${FILE_URL:-file:///src/core/pkg}
        var_SYNC_URL=${SYNC_URL:-}
}

worker_install_packages()
{
    inform "Package installation started..."
    # from dieter's examples in unofficial subdir of aif github repo
    # better to do this here rather than redefine PACMAN & PACMAN_TARGET?
#    PACMAN_BACKUP=$PACMAN
#    PACMAN_TARGET_BACKUP=$PACMAN_TARGET
#    PACMAN=${PACMAN//pacman/yaourt}
#    PACMAN_TARGET=${PACMAN_TARGET//pacman/yaourt}

    debug_report_values "SOURCE FILE_URL SYNC_URL var_RUNTIME_REPOSITORIES var_MIRRORLIST var_PKG_SOURCE_TYPE var_FILE_URL var_SYNC_URL var_TARGET_DIR var_TARGET_PACKAGES"

    # target_prepare_pacman core extra community && installpkg
#    target_prepare_pacman core extra community && echo ">>>>>>>>>>>>>>>RETURNED $?" && installpkg
    target_prepare_pacman core extra community
    echo ">>>>>>>>>>>>>>>RETURNED $?"
    echo "press enter"
    read answer
    installpkg

    debug_report_values "SOURCE FILE_URL SYNC_URL var_RUNTIME_REPOSITORIES var_MIRRORLIST var_PKG_SOURCE_TYPE var_FILE_URL var_SYNC_URL var_TARGET_DIR var_TARGET_PACKAGES"

#    target_prepare_pacman core extra community
#    [[ -n "$TARGET_PACKAGES" ]] && installpkg || die_error "No packages listed for installation!"
    
    #PACMAN=$PACMAN_BACKUP
    #PACMAN_TARGET=$PACMAN_TARGET_BACKUP
}

worker_write_configs()
{
    inform "Configuration write started"
    write_configs $CONFIG_CHANGES
}

worker_write_overlay()
{
    inform "Overlay write started..."
    # This is more problematic as we have to include the correct prefix path
    # and make sure to source it properly if local/remote, etc.
    # the add overlay files function will have to correctly assign a full path
    write_overlay $var_OVERLAY_FILES
}

worker_system_misc ()
{
    inform "Misc. system additions started..."
    system_misc
}

# ----------------------------------------------------------------------
# ----------------------------------------------------------------------
# library functions
# ----------------------------------------------------------------------
# ----------------------------------------------------------------------
# These should ideally be stored in the module libs directory as an
# actual function library, but as we are loading the procedure remotely
# it's better to bundle them here. Alternately we could try to 
# manufacture a libs path from the remote procedure, but this adds
# potentially needless complexity. TODO: consider breaking out a 
# separate lib and creating a remote lib sourcing function in future

# ----------------------------------------------------------------------
# lib-archproto
# ----------------------------------------------------------------------
# functions to support archproto procedure itself

d() { debug PROCEDURE "$1"; }
dstate() { d "ARCHPROTO STATECHK: $1 is currently: ${!1}"; }
dfunc()
{
    # quick debug function, better info than "caller"
    # called without parameters at top of function; reports where it was called 
    # from (calling function and line number)
    [[ $1 ]] && local with_args=" with arguments \"$@\"" || local with_args=""
    d "ARCHPROTO FUNCTION: ${FUNCNAME[1]}() called at line ${BASH_LINENO[1]} by ${FUNCNAME[2]}${with_args}"
}

set_values_with_default_fallbacks ()
{
    dfunc "$*"
    local valuelist=$@
    for valname in $valuelist
    do
        defaultval=default_$valname; eval $valname=\'"${!valname:-$defaultval}"\'
    done
}

process_args ()
{
    dfunc
    var_AUTOMATIC_PROFILE=
    while [[ -n $1 ]]
    do
        case $1 in
            -c) [[ -n "$2" ]] && var_AUTOMATIC_PROFILE=$2 || die_error "You must specify an aif config profile when using the -c flag." ;;
            -r) [[ -n "$2" ]] && var_REPO_TYPE=$2 || die_error "You must specify a repository type of git, hg, or svn with the -r flag." ;;
            *) usage && exit 5 ;;
        esac
        shift 2
    done
}

source_and_overlay()
{
    # TODO: consider refactoring this to an array
    dfunc "$*"
    local revert_overlay=$var_OVERLAY_PATH
    var_OVERLAY_PATH="$(dirname "$1")/overlay"
    source "$1" && inform "ARCHPROTO PROFILE: Successfully processed profile:\n${1#$var_DOWNLOADS_DIR}" \
                || die_error "ARCHPROTO PROFILE: Failed to process profile \"$1\"."
    var_OVERLAY_PATH=$revert_overlay
} 

make_local ()
{
    # takes a remote repo path and returns a local path (dies if repo can't be cloned)
    local  __returnvarname=${2:-} # can take a variable name to assign result to (otherwise returns value via echo

    dfunc

    # repo remote is almost certainly never going to be an actual repo path
    # but rather a full path to a file in a repo. This is complicated by the fact that we want to provide aif an actual file for it's initial procedure and
    # subsequently use that repo information (extracted from the raw path). The infix values below should clean this up for us, but needs more testing
    local full_path_remote=$1

    # detect/set repo_type
    local repo_type=${var_REPO_TYPE:-} # from optional -r command line argument
    if [[ -n "$repo_type" ]]; then : # $repo_type already set
    elif [ $(expr "$full_path_remote" : 'https*://.*github.com') -gt 0 ]; then repo_type=git
    elif [ $(expr "$full_path_remote" : '.*/git/') -gt 0 ]; then repo_type=git
    elif [ $(expr "$full_path_remote" : 'https*://.*bitbucket.org') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$full_path_remote" : '.*/hg/') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$full_path_remote" : '.*/mercurial/') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$full_path_remote" : 'https*://code.google.com') -gt 0 ]; then repo_type=svn
    elif [ $(expr "$full_path_remote" : '.*/trunk/') -gt 0 ]; then repo_type=svn
    elif [ $(expr "$full_path_remote" : '.*/svn/') -gt 0 ]; then repo_type=svn
    fi

    # now set the repo clone command, infix to strip out github/bitbucket raw file path values, and any suffix required to clone (.git)
    local repo_command=
    local repo_suffix=
    local repo_infix=
    case $repo_type in
        git)
                repo_command="git clone --depth=0"
                repo_suffix=".git"
                repo_infix="raw[./][^/]*/" # raw/master/
        ;;
        hg|mercurial)
                repo_command="hg clone"
                repo_infix="raw[./][^/]*/[^/]*/" # raw/32dc76fda832/src/
        ;;
        svn)
                repo_command="svn checkout"
                # google code, at least, doesn't stick in any infixes for the raw file
                # but does present a different url for the raw file. this url works for cloning, however
                # http://code.google.com/p/googlecl/source/browse/trunk/INSTALL.txt
                # http://googlecl.googlecode.com/svn/trunk/INSTALL.txt
                # I haven't tested other svn services yet
        ;;
    esac

    # strip infix out of remote path, allowing us to just use makelocal after this
    # all paths passed to this function must be treated as suspect as any of them
    # could be raw format paths. for example, this converts the following github url:
    # PRE INFIX STRIP:  http://github.com/altercation/archproto/raw/master/procedures/automatic/systems/lenovo/x220
    # POST INFIX STRIP: http://github.com/altercation/archproto/procedures/automatic/systems/lenovo/x220
    full_path_remote=$(echo -n "$full_path_remote" | sed "s^$repo_infix^^")

    # at this point, we have cleaned up our full remote path and identified what kind of repo it is
    # the repo may still be already cloned locally. normally if the user specifies a full remote
    # procedure path and then a relative path for the profile, we will add the local repo module
    # root to our var_MODULE_PATHS array and won't normally have to double check if the repo is already
    # present. However, if someone passes identical repo paths in both the aif procedure command line
    # argument and the profile argument (or embedded in a depend_profile command in a profile), we
    # need to be ready to handle it here

    # make a local path for the profile file for an initial file check and, failing that, cloning, for example:
    # REMOTE:                       http://github.com/altercation/archproto/procedures/automatic/systems/lenovo/x220
    # LOCAL:  /tmp/aif/archproto-downloads/github.com/altercation/archproto/procedures/automatic/systems/lenovo/x220
    local full_path_local="$var_DOWNLOADS_DIR/${full_path_remote:$(expr "$full_path_remote" : 'https*://')}"

    # we can now use that profile path to clone the remote repo by cloning, failing, and trimming until we get down to the actual repo root.
    # this is a bit brute force and we could be smarter about it if we wanted to supply an actual template for the repo root, for example
    # github's pattern is github.com/username/reponame
    # that's left for a later optimization round. even with that we should support private repository urls (or unknown or less popular services)
    # that have unknown URL formats. brute force try/trim/iterate does this for now.

    local repo_remote="$full_path_remote" # initial repo_remote assignment
    local repo_local="$var_DOWNLOADS_DIR/${repo_remote:$(expr "$repo_remote" : 'https*://')}"

    while [[ -n "$repo_remote" && ${#repo_remote} > 1 ]]; do # loop till we trim too much, indicating profound failure

        if [[ -e "$full_path_local" ]]; then # found local file
            [[ "$__returnvarname" ]] && eval $__returnvarname="'$full_path_local'" || echo "$full_path_remote"
            return 0
        elif $repo_command $repo_remote $repo_local &>/dev/null; then # successful clone
                # we return the local path and load_profile can handle adding it to the path
                [[ "$__returnvarname" ]] && eval $__returnvarname="'$full_path_local'" || echo "$full_path_remote"
                return 0
        else # clone failed
                rm -rf "$(dirname $repo_local)" # clean up bad repo path
        fi

        # trim and retry
        repo_remote=$(dirname "$repo_remote")
        repo_local="$var_DOWNLOADS_DIR/${repo_remote:$(expr "$repo_remote" : 'https*://')}"
    done; die_error "failed to download repo from path $1"
}
update_modulepaths_from_profilepath()
{
    dfunc "$*"
    # expects parameters:
    # $1: a local absolute path or http remote *profile* path we need to make some assumptions about either the depth of all profile paths or standard names 
    # such as procedure, systems, etc. this is the trickiest assumption we make and the only other option I see is to never allow a relative path, which is silly.
    # requires state: $var_KNOWN_SUBDIRS
    # modifies state: $var_MODULE_PATHS
    local module_path=${1%profile} # strip profile
    module_path=${module_path%/} # strip trailing slash
    while [[ -n "$module_path" && ${#module_path} > 1 ]]; do
        for known_subdir in ${var_KNOWN_SUBDIRS[@]}; do
            if [[ "$(basename $module_path)" == "$known_subdir" ]]
            then
                # we have a match and assume we are one level away from root || trim and loop
                module_path="$(dirname $module_path)"
                # now check to see if this path is already in var_MODULE_PATHS
                for test_path in ${var_MODULE_PATHS[@]}; do [[ "$test_path" == "$module_path" ]] && return 0; done
                # still here, add path to var_MODULE_PATHS
                var_MODULE_PATHS=("$module_path" "${var_MODULE_PATHS[@]}")
                d "ARCHPROTO STATECHK: var_MODULE_PATHS updated to: ${var_MODULE_PATHS[*]}"
                return 0
            fi
        done
        module_path="$(dirname $module_path)" # no match, trim a level
    done
    # if we are still here then we didn't find a "known subdir"... best to error out here, though another option is to just strip the last two / three 
    # path components. we could try to standardize all "known" subdir formats to: modulename/knownsubidr/category/specificprofile, eg:
    # archproto/systems/lenovo/x220 or archproto/environments/xmonad/es
    die_error "failed to find known subdirectory (one of ${var_KNOWN_SUBDIRS[@]}) in path $1;"
}

load_profile()
{
    dfunc "$*"
    # arguments:
    # $1 (assigned to profile_path): a path, either relative, absolute local or remote URL
    # $2 is the *original* type of profile (relative, remote, absolute) and is only set from insid the function
    # expects/uses state:
    # OVERLAY: current value of OVERLAY directory path
    # var MODULE_PATHS: array of paths to use, in order, as module roots with relative paths
    local profile_path=${1%/} # strips any trailing slash
    local profile_type=${2:-} # only used internally in this function
    if [[ "${profile_path:0:1}" == "/" ]]; then # absolute local path
        # add to module paths (thus if we've donwloaded a repo, we'll check locally next time)
        [[ "${profile_type}" != "xrelative" ]] && update_modulepaths_from_profilepath "$profile_path"
        [[ -d "${profile_path}" ]] && profile_path="$profile_path/profile"
        [[ -f "${profile_path}" ]] && source_and_overlay "$profile_path" || return 1
    elif [[ "${profile_path:0:4}" == "http" ]]; then # remote url, could be http or https with this match
        if make_local $profile_path profile_path_local
        then
                d "ARCHPROTO PROFILES: preparing to load profile $profile_path_local"
                load_profile "$profile_path_local" ${profile_type:-http} || return 1
        else
                die_error "should definitely not reach this error. there was a problem getting the local profile path from a remote repo."
        fi
    else # assumed relative path (e.g. profiles/profilename)
        for module_root in ${var_MODULE_PATHS[@]}; do load_profile "${module_root%/}/${profile_path#/}" "relative" && return 0; done; return 1
    fi
}

write_configs()
{
        dfunc
        # iterate through array of config changes
        # write changes using augeas or custom function
}

write_overlay()
{
        # TODO: consider just moving/copying *all* files in overlay without any specification, or perhaps allow a special overlay value of "*"
        # TODO: we might need to set certain permissions, but i'd rather leave this for the misc step
        #       i could also make the system_misc function or worker process an array of commands; here we use installs permissions arg
        dfunc
        echo "TARGET=$var_TARGET_DIR"
        for overlay_file in $var_OVERLAY_FILES
        do
                # TODO: the following substitution performs differently in script vs command line;
                # command line *requires* last slash to be escaped like this:
                # from_path="${overlay_file/\/\//\/}"
                # script *requires* last slash to *not* be escaped, so we use that here
                from_path="${overlay_file/\/\///}"

                to_path="$var_TARGET_DIR/${overlay_file#*\/\/}"
                # TODO: test if permissions are retained via --preserve-context
                # TODO: confirm backups are created correctly
                install -C -D -S ".archproto.old" --preserve-context -v -T "$from_path" "$to_path" \
                || die_error "failed to overlay file from \"$from_path\" to \"$to_path\""
        done
}

# ----------------------------------------------------------------------
# lib-profiles
# ----------------------------------------------------------------------
# functions to support archproto profiles

depend_profile() { load_profile "$1"; }
add_package() { dfunc; [[ -n "$*" ]] && TARGET_PACKAGES+="$*"; dstate TARGET_PACKAGES; }
add_configs() { dfunc; [[ -n "$*" ]] && CONFIG_CHANGES+="$*"; dstate CONFIG_CHANGES; }
add_overlay()
{
    dfunc
    if [[ -n "$*" ]]
    then
        for overlay_file in $*
        do
            var_OVERLAY_FILES+=" $var_OVERLAY_PATH//${overlay_file#/}" # strip any leading slash (should have one) and add a double slash
        done
    fi
    dstate var_OVERLAY_FILES;
}
system_misc() { dfunc; } # this can be overidden in a user profile (note that only final override executes)

#set_value /etc/rc.conf valuename value

#set_config
#unset_config
#add_daemon
#remove_daemon
#add_module
#remove_module
#augeas_raw

# TODO: consider refactoring this with augeas
get_config()
{
    local config_file="$1"; local config_name="$2"; local config_value="$3"; local config_line=$(egrep "^[[:space:]]*${config_name}" "${config_file}")
    [[ -n $config_line ]] && (echo -n $config_line | sed "s/.*$config_name.*=[[:space:]]*\(.*\)[[:space:]]*$/\1/"; return 0) || (return 1)
}

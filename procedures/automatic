#!/bin/bash

# Ethan Schoonover <es@ethanschoonover.com>

# command line tests:
# aif -p http://github.com/altercation/archproto/raw/master/procedures/automatic -c systems/lenovo/x220
# aif -p archproto/automatic -c https://github.com/altercation/archproto/systems/lenovo/x220/profile

# archproto/automatic
# aif procedure to install a various prototype configurations
# including hardware prototypes for specific makes/models,
# environment prototypes for common wm/de configurations
# application set prototypes (e.g. lightweight-cli apps)
# user protytpes

# also takes a user customized aif profile using archproto specific functions

# defined herein:
#
# additional custom worker(s)
# custom command line parameter handling
# revised http remote module sourcing to enable overlay, etc.
# revised profile/config source heuristic to be smart (but not too smart) about 
# where to get the specified profiles from
# addition to phases to include correct worker(s)
#
# we also define and redefine some lib functions, notably those related to 
# loading libs, files, etc. The reason for these redefined functions is that we 
# want to be able to source those file remotely, be smart (but not too smart) 
# about the path searched for those files and enable loading new types of files 
# such as the system prototype profiles. Finally we have to redefine these here 
# rather than a library script because this is the only file we can load from 
# aif remotely.

# ----------------------------------------------------------------------
# procedure specific definitions
# ----------------------------------------------------------------------

[[ "$NOFAILSAFE" != "1" && ! -e /arch ]] && die_error "FAILSAFE TRIPPED: no /arch directory present, looks like an installed system\nOverride this by: \`export NOFAILSAFE=1\`"

depend_procedure core automatic # most of automatic fits our needs, up top so we can override the phases and values it sets below

ARCHPROTO_MODULE_NAME=archproto # in case we need to change our script name 
ARCHPROTO_PROCEDURE_SUBPATH=/procedures/automatic
DOWNLOADS_DIR="${RUNTIME_DIR}/${ARCHPROTO_MODULE_NAME}-downloads"; [[ -e "$DOWNLOADS_DIR" ]] && rm -rf "$DOWNLOADS_DIR"; mkdir -p "$DOWNLOADS_DIR"
KNOWN_SUBDIRS=(procedures libs profiles systems environments applications users examples) # standard subdirectory names for archproto/aif
[[ "$module" != "http" ]] && AIF_PROCEDURE_PATH="$procedure" || AIF_PROCEDURE_PATH="$2"; MODULE_PATHS[0]="${AIF_PROCEDURE_PATH%$ARCHPROTO_PROCEDURE_SUBPATH*}"
var_RUNTIME_REPOSITORIES=(archlinuxfr "http://repo.archlinux.fr/${var_ARCH}")
var_RUNTIME_PACKAGES="git yaourt" # var_RUNTIME_PACKAGES="yaourt git mercurial svn augeas"
var_OPTS_STRING="c:r:" #var_OPTS_STRING="c:s:e:u:a:r:"

#phase_preparation=(runtime_network runtime_repositories runtime_packages configure profile intro sysprep select_source)
#phase_basics=()
#phase_system=()
phase_preparation=(runtime_network runtime_repositories runtime_packages configure profile intro select_source)
phase_basics=(set_clock prepare_disks) # defaults, here for ref/override
phase_system=(package_list install_packages configure_system install_bootloader) # defaults, here for ref/override
phase_system+=(write_configs write_overlay system_misc) # archproto custom workers (see below)
phase_finish=(msg_report) # defaults

# !!!!!TODO: it's possible we have to call some reconfig at end of phase_system due to possible changes impacting mkinitcpio
# the worker to call is configure_system. it's actually ok to call the second default function (post_configure target) several times
# though maybe better to either redefine configure_system, move it to the end, or have another post-configure worker at the end of the phase_system

# ---------------------------------------------------------------------
# following two lines from dieter's automatic procedure, for ref
# TODO: implement setting hostname, keymap, consolefont, network settings, root 
# for a list of recognized variables, see examples/generic-install-on-sda
# ---------------------------------------------------------------------

read -r -d '' var_ARGS_USAGE <<-'EOF'
-s <make/model>:    Specify a make/model prototype AIF system profile to install. If specified as simply "make/model" the path of the 
                    archproto module as specified in the -p parameter will be used. This allows for specifying the following:

                        aif -p archproto/automatic -s lenovo/x120e

                    and aif will automatically source the system profile from:
EOF

# ----------------------------------------------------------------------
# procedure workers
# ----------------------------------------------------------------------

worker_intro ()
{
    notify "AIF archproto automatic procedure using initial profile $archproto_PROFILE"
}

worker_runtime_packages ()
{
    $PACMAN -Sy pacman --noconfirm || return 1 # update pacman first to avoid having to run twice
    for pkg in $var_RUNTIME_PACKAGES; do $PACMAN -Sy --noconfirm --needed $pkg || return 1; done
    #PACMAN=yaourt
    return 0
}

worker_configure ()
{
    var_UI_TYPE=${arg_ui_type:-cli}
    ui_init
    [ -z "$var_AUTOMATIC_PROFILE" ] && die_error "You must specify a config file to use this procedure"
    # Check mandatory options
    # initialize internal variables based on variables set by the user (some of the vars are handled in other workers):
    var_RUNTIME_REPOSITORIES=$RUNTIME_REPOSITORIES
    var_RUNTIME_PACKAGES=$RUNTIME_PACKAGES
    var_GRUB_DEVICE=$GRUB_DEVICE
    var_PARTITIONS=$PARTITIONS
    var_BLOCKDATA=$BLOCKDATA
    HARDWARECLOCK=${HARDWARECLOCK:-localtime}
    TIMEZONE=${TIMEZONE:-Canada/Pacific}
}

worker_profile ()
{
    notify "Starting profile load..."
    load_profile $var_AUTOMATIC_PROFILE || die_error "Failed to load profile $var_AUTOMATIC_PROFILE from paths $MODULE_PATHS"
    [ -z "$PARTITIONS" ] && die_error "You did not specify a partition scheme"
    [ -z "$BLOCKDATA"  ] && die_error "You did not specify a partition scheme"
    [ -z "$GRUB_DEVICE" ] && die_error "You did not specify a grub device"
}

worker_install_packages()
{
    notify "Package installation started..."
    exit
    # from dieter's examples in unofficial subdir of aif github repo
    # better to do this here rather than redefine PACMAN & PACMAN_TARGET?
    true
    return
#    PACMAN_BACKUP=$PACMAN
#    PACMAN_TARGET_BACKUP=$PACMAN_TARGET
#    PACMAN=${PACMAN//pacman/yaourt}
#    PACMAN_TARGET=${PACMAN_TARGET//pacman/yaourt}
    
    target_prepare_pacman core extra community
    [[ -n "$TARGET_PACKAGES" ]] && installpkg || die_error "No packages listed for installation!"
    
    PACMAN=$PACMAN_BACKUP
    PACMAN_TARGET=$PACMAN_TARGET_BACKUP
}

worker_write_configs()
{
    notify "Configuration write started"
    write_configs $CONFIG_CHANGES
}

worker_write_overlay()
{
    notify "Overlay write started..."
    # This is more problematic as we have to include the correct prefix path
    # and make sure to source it properly if local/remote, etc.
    # the add overlay files function will have to correctly assign a full path
    write_overlay $OVERLAY_FILES
}

worker_system_misc ()
{
    notify "Misc. system additions started..."
    system_misc
}
process_disks ()
{
        while read disk scheme
        do
                echo "=================> disk is $disk"
                echo "=================> scheme is $scheme"
                sleep 3 
                process_disk $disk "$scheme" || return $?
        done < $TMP_PARTITIONS
}

worker_prepare_disks ()
{
        echo ">>>>>????????????????////////////////"
        echo ">>>>>????????????????////////////////"
        echo ">>>>>????????????????////////////////"
        echo ">>>>>????????????????////////////////"
sleep 5
        get_possible_fs
        echo "$var_PARTITIONS" > $TMP_PARTITIONS
        echo "$var_BLOCKDATA" > $TMP_BLOCKDEVICES
        process_disks       || die_error "Could not process_disks"
        if ! process_filesystems
        then
                show_warning 'Disk processing' "Could not process_filesystems"
                txt='also failed to execute properly'
                rollback_filesystems && txt='ended successfully'
                die_error "Something failed while processing the filesystem.  A rollback was executed, which $txt"
        fi
        inform "Partitions and filesystems made successfully"

        # TODO: fstab? auto-add to fstab with libs? auto mkdir's on target_dir?
}

# ----------------------------------------------------------------------
# ----------------------------------------------------------------------
# library functions
# ----------------------------------------------------------------------
# ----------------------------------------------------------------------
# These should ideally be stored in the module libs directory as an
# actual function library, but as we are loading the procedure remotely
# it's better to bundle them here. Alternately we could try to 
# manufacture a libs path from the remote procedure, but this adds
# potentially needless complexity. TODO: consider breaking out a 
# separate lib and creating a remote lib sourcing function in future

# ----------------------------------------------------------------------
# lib-archproto
# ----------------------------------------------------------------------
# functions to support archproto procedure itself

d() { debug PROCEDURE "$1"; }
dstate() { d "ARCHPROTO STATECHK: $1 is currently: ${!1}"; }
dfunc()
{
    # quick debug function, better info than "caller"
    # called without parameters at top of function; reports where it was called 
    # from (calling function and line number)
    [[ $1 ]] && local with_args=" with arguments \"$@\"" || local with_args=""
    d "ARCHPROTO FUNCTION: ${FUNCNAME[1]}() called at line ${BASH_LINENO[1]} by ${FUNCNAME[2]}${with_args}"
}

process_args ()
{
    dfunc
    var_AUTOMATIC_PROFILE=
    while [[ -n $1 ]]
    do
        case $1 in
            -c) [[ -n "$2" ]] && var_AUTOMATIC_PROFILE=$2 || die_error "You must specify an aif config profile when using the -c flag." ;;
            -r) [[ -n "$2" ]] && REPO_TYPE=$2 || die_error "You must specify an aif config profile when using the -c flag." ;;
            *) usage && exit 5 ;;
        esac
        shift 2
    done
}

source_and_overlay()
{
    # TODO: consider refactoring this to an array
    dfunc "$*"
    local revert_overlay=$OVERLAY_PATH
    OVERLAY_PATH="$(dirname "$1")/overlay"
    source $1 && notify "Successfully processed values in profile \"$1\"" || die_error "Failed to process profile \"$1\"."
    OVERLAY_PATH=$revert_overlay
    echo "-------------- $PARTITIONS ------------------123"
} 

make_local ()
{
    # takes a remote repo path and returns a local path (dies if repo can't be cloned)
    local  __returnvarname=${2:-} # can take a variable name to assign result to (otherwise returns value via echo

    dfunc

    # repo remote is almost certainly never going to be an actual repo path
    # but rather a full path to a file in a repo. This is complicated by the fact that we want to provide aif an actual file for it's initial procedure and
    # subsequently use that repo information (extracted from the raw path). The infix values below should clean this up for us, but needs more testing
    local full_path_remote=$1

    # detect/set repo_type
    local repo_type=${REPO_TYPE:-} # from optional -r command line argument
    if [[ -n "$repo_type" ]]; then : # $repo_type already set
    elif [ $(expr "$full_path_remote" : 'https*://.*github.com') -gt 0 ]; then repo_type=git
    elif [ $(expr "$full_path_remote" : '.*/git/') -gt 0 ]; then repo_type=git
    elif [ $(expr "$full_path_remote" : 'https*://.*bitbucket.org') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$full_path_remote" : '.*/hg/') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$full_path_remote" : '.*/mercurial/') -gt 0 ]; then repo_type=hg
    elif [ $(expr "$full_path_remote" : 'https*://code.google.com') -gt 0 ]; then repo_type=svn
    elif [ $(expr "$full_path_remote" : '.*/trunk/') -gt 0 ]; then repo_type=svn
    elif [ $(expr "$full_path_remote" : '.*/svn/') -gt 0 ]; then repo_type=svn
    fi

    # now set the repo clone command, infix to strip out github/bitbucket raw file path values, and any suffix required to clone (.git)
    local repo_command=
    local repo_suffix=
    local repo_infix=
    case $repo_type in
        git)
                repo_command="git clone --depth=0"
                repo_suffix=".git"
                repo_infix="raw[./][^/]*/" # raw/master/
        ;;
        hg)
                repo_command="hg clone"
                repo_infix="raw[./][^/]*/[^/]*/" # raw/32dc76fda832/src/
        ;;
        svn)
                repo_command="svn checkout"
                # google code, at least, doesn't stick in any infixes for the raw file
                # but does present a different url for the raw file. this url works for cloning, however
                # http://code.google.com/p/googlecl/source/browse/trunk/INSTALL.txt
                # http://googlecl.googlecode.com/svn/trunk/INSTALL.txt
                # I haven't tested other svn services yet
        ;;
    esac

    # strip infix out of remote path, allowing us to just use makelocal after this
    # all paths passed to this function must be treated as suspect as any of them
    # could be raw format paths. for example, this converts the following github url:
    # PRE INFIX STRIP:  http://github.com/altercation/archproto/raw/master/procedures/automatic/systems/lenovo/x220
    # POST INFIX STRIP: http://github.com/altercation/archproto/procedures/automatic/systems/lenovo/x220
    full_path_remote=$(echo -n "$full_path_remote" | sed "s^$repo_infix^^")

    # at this point, we have cleaned up our full remote path and identified what kind of repo it is
    # the repo may still be already cloned locally. normally if the user specifies a full remote
    # procedure path and then a relative path for the profile, we will add the local repo module
    # root to our MODULE_PATHS array and won't normally have to double check if the repo is already
    # present. However, if someone passes identical repo paths in both the aif procedure command line
    # argument and the profile argument (or embedded in a depend_profile command in a profile), we
    # need to be ready to handle it here

    # make a local path for the profile file for an initial file check and, failing that, cloning, for example:
    # REMOTE:                       http://github.com/altercation/archproto/procedures/automatic/systems/lenovo/x220
    # LOCAL:  /tmp/aif/archproto-downloads/github.com/altercation/archproto/procedures/automatic/systems/lenovo/x220
    local full_path_local="$DOWNLOADS_DIR/${full_path_remote:$(expr "$full_path_remote" : 'https*://')}"

    # we can now use that profile path to clone the remote repo by cloning, failing, and trimming until we get down to the actual repo root.
    # this is a bit brute force and we could be smarter about it if we wanted to supply an actual template for the repo root, for example
    # github's pattern is github.com/username/reponame
    # that's left for a later optimization round. even with that we should support private repository urls (or unknown or less popular services)
    # that have unknown URL formats. brute force try/trim/iterate does this for now.

    local repo_remote="$full_path_remote" # initial repo_remote assignment
    local repo_local="$DOWNLOADS_DIR/${repo_remote:$(expr "$repo_remote" : 'https*://')}"

    while [[ -n "$repo_remote" && ${#repo_remote} > 1 ]]; do # loop till we trim too much, indicating profound failure

        if [[ -e "$full_path_local" ]]; then # found local file
            [[ "$__returnvarname" ]] && eval $__returnvarname="'$full_path_local'" || echo "$full_path_remote"
            return 0
        elif $repo_command $repo_remote $repo_local &>/dev/null; then # successful clone
                # we return the local path and load_profile can handle adding it to the path
                [[ "$__returnvarname" ]] && eval $__returnvarname="'$full_path_local'" || echo "$full_path_remote"
                return 0
        else # clone failed
                rm -rf "$(dirname $repo_local)" # clean up bad repo path
        fi

        # trim and retry
        repo_remote=$(dirname "$repo_remote")
        repo_local="$DOWNLOADS_DIR/${repo_remote:$(expr "$repo_remote" : 'https*://')}"
    done; die_error "failed to download repo from path $1"
}
update_modulepaths_from_profilepath()
{
    dfunc "$*"
    # expects parameters:
    # $1: a local absolute path or http remote *profile* path we need to make some assumptions about either the depth of all profile paths or standard names 
    # such as procedure, systems, etc. this is the trickiest assumption we make and the only other option I see is to never allow a relative path, which is silly.
    # requires state: $KNOWN_SUBDIRS
    # modifies state: $MODULE_PATHS
    local module_path=${1%profile} # strip profile
    module_path=${module_path%/} # strip trailing slash
    while [[ -n "$module_path" && ${#module_path} > 1 ]]; do
        for known_subdir in ${KNOWN_SUBDIRS[@]}; do
            if [[ "$(basename $module_path)" == "$known_subdir" ]]
            then
                # we have a match and assume we are one level away from root || trim and loop
                module_path="$(dirname $module_path)"
                # now check to see if this path is already in MODULE_PATHS
                for test_path in ${MODULE_PATHS[@]}; do [[ "$test_path" == "$module_path" ]] && return 0; done
                # still here, add path to MODULE_PATHS
                MODULE_PATHS=("$module_path" "${MODULE_PATHS[@]}")
                d "ARCHPROTO STATECHK: MODULE_PATHS updated to: ${MODULE_PATHS[*]}"
                return 0
            fi
        done
        module_path="$(dirname $module_path)" # no match, trim a level
    done
    # if we are still here then we didn't find a "known subdir"... best to error out here, though another option is to just strip the last two / three 
    # path components. we could try to standardize all "known" subdir formats to: modulename/knownsubidr/category/specificprofile, eg:
    # archproto/systems/lenovo/x220 or archproto/environments/xmonad/es
    die_error "failed to find known subdirectory (one of ${KNOWN_SUBDIRS[@]}) in path $1;"
}

load_profile()
{
    dfunc "$*"
    # arguments:
    # $1 (assigned to profile_path): a path, either relative, absolute local or remote URL
    # $2 is the *original* type of profile (relative, remote, absolute) and is only set from insid the function
    # expects/uses state:
    # OVERLAY: current value of OVERLAY directory path
    # MODULE_PATHS: array of paths to use, in order, as module roots with relative paths
    local profile_path=${1%/} # strips any trailing slash
    local profile_type=${2:-} # only used internally in this function
    if [[ "${profile_path:0:1}" == "/" ]]; then # absolute local path
        # add to module paths (thus if we've donwloaded a repo, we'll check locally next time)
        [[ "${profile_type}" != "xrelative" ]] && update_modulepaths_from_profilepath "$profile_path"
        [[ -d "${profile_path}" ]] && profile_path="$profile_path/profile"
        [[ -f "${profile_path}" ]] && source_and_overlay "$profile_path" || return 1
    elif [[ "${profile_path:0:4}" == "http" ]]; then # remote url, could be http or https with this match
        if make_local $profile_path profile_path_local
        then
                d "ARCHPROTO PROFILES: preparing to load profile $profile_path_local"
                load_profile "$profile_path_local" ${profile_type:-http} || return 1
        else
                die_error "should definitely not reach this error. there was a problem getting the local profile path from a remote repo."
        fi
    else # assumed relative path (e.g. profiles/profilename)
        for module_root in ${MODULE_PATHS[@]}; do load_profile "${module_root%/}/${profile_path#/}" "relative" && return 0; done; return 1
    fi
}

write_configs()
{
        dfunc
        # iterate through array of config changes
        # write changes using augeas or custom function
}

write_overlay()
{
        # TODO: consider just moving/copying *all* files in overlay without any specification, or perhaps allow a special overlay value of "*"
        # TODO: we might need to set certain permissions, but i'd rather leave this for the misc step
        #       i could also make the system_misc function or worker process an array of commands; here we use installs permissions arg
        dfunc
        echo "TARGET=$var_TARGET_DIR"
        for overlay_file in $OVERLAY_FILES
        do
                from_path="${overlay_file/\/\///}" # TODO: this substitution performs differently in script vs command line; command line requires last slash to be escaped; here not
                to_path="$var_TARGET_DIR/${overlay_file#*\/\/}"
                # TODO: test if permissions are retained via --preserve-context
                # TODO: confirm backups are created correctly
                install -C -D -S ".archproto.old" --preserve-context -v -T "$from_path" "$to_path" || die_error "failed to overlay file from \"$from_path\" to \"$to_path\""
        done
}

# ----------------------------------------------------------------------
# lib-profiles
# ----------------------------------------------------------------------
# functions to support archproto profiles

depend_profile() { load_profile "$1"; }
add_package() { dfunc; [[ -n "$*" ]] && TARGET_PACKAGES+="$*"; dstate TARGET_PACKAGES; }
add_configs() { dfunc; [[ -n "$*" ]] && CONFIG_CHANGES+="$*"; dstate CONFIG_CHANGES; }
add_overlay()
{
    dfunc
    if [[ -n "$*" ]]
    then
        for overlay_file in $*
        do
            OVERLAY_FILES+=" $OVERLAY_PATH//${overlay_file#/}" # strip any leading slash (should have one) and add a double slash
        done
    fi
    dstate OVERLAY_FILES;
}
system_misc() { dfunc; } # this can be overidden in a user profile (note that only final override executes)

#set_value /etc/rc.conf valuename value

#set_config
#unset_config
#add_daemon
#remove_daemon
#add_module
#remove_module
#augeas_raw

# TODO: consider refactoring this with augeas
get_config()
{
    local config_file="$1"; local config_name="$2"; local config_value="$3"; local config_line=$(egrep "^[[:space:]]*${config_name}" "${config_file}")
    [[ -n $config_line ]] && (echo -n $config_line | sed "s/.*$config_name.*=[[:space:]]*\(.*\)[[:space:]]*$/\1/"; return 0) || (return 1)
}
